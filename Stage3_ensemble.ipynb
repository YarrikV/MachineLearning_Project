{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: Full Pipeline with Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing \n",
    "\n",
    "## 1.1 Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm \n",
    "import shutil\n",
    "from data.util import *\n",
    "from data.transformer import * \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import RFE,RFECV #importing RFE class from sklearn library\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "# load training and testing data into memory\n",
    "root_path = \"data3\"\n",
    "X_train, s_train, y_train_str, p_train, i_train = TrainDataLoader(root_path).load()\n",
    "X_test = TestDataLoader(root_path).load()\n",
    "X_train, s_train, y_train_str, p_train, i_train = TrainDataLoader(root_path).load()\n",
    "\n",
    "# X_train: all features (pixels x 3) of all training samples (4146)\n",
    "# s_train: superclasses of all samples (4146); note ordered\n",
    "# y_train: classes of all samples (4146); note ordered\n",
    "# p_train: pole IDs of all samples (4146)\n",
    "# i_train: indices of all samples (4146); note duplicates\n",
    "# X_test: all features (pixels x 3) of all testing samples (4293)\n",
    "\n",
    "# Make sure that you properly encode the CLASSES such that \n",
    "# the order in your submission files is correct!\n",
    "label_enc = LabelEncoder()\n",
    "label_enc.fit(CLASSES)\n",
    "y_train = label_enc.transform(y_train_str) # numerical labels\n",
    "    \n",
    "# Randomizer\n",
    "numpy_seed = 0\n",
    "python_seed = 0\n",
    "np.random.seed(numpy_seed)\n",
    "random.seed(python_seed)\n",
    "\n",
    "# display some numbers\n",
    "number_of_train_samples = len(X_train)\n",
    "number_of_classes = len(np.unique(y_train))\n",
    "number_of_test_samples = len(X_test)\n",
    "print('number of training samples:', number_of_train_samples)\n",
    "print('number of testing samples:', number_of_test_samples)\n",
    "print('number of labels:', number_of_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot showing the class distribution in the training set\n",
    "fig_distr, ax_distr = plt.subplots()\n",
    "ax_distr.set_title(\"The class distribution of the training set\")\n",
    "ax_distr.set_xlabel(\"Classes\")\n",
    "ax_distr.set_ylabel(\"Number of samples\")\n",
    "\n",
    "count = countOcc(y_train)\n",
    "plt.plot([i for i in range(len(count))], count);\n",
    "fig_distr.savefig(os.path.join('visualization','class_distribution.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Improve contrast (CLAHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_contr = ContrastTransformer().transform(X_train)\n",
    "X_test_contr = ContrastTransformer().transform(X_test)\n",
    "\n",
    "# Show effect of improving contrast\n",
    "image_index = 99\n",
    "image_ori = Image.fromarray(X_train[image_index])\n",
    "image_con = Image.fromarray(X_train_contr[image_index])\n",
    "\n",
    "# create figure and show images\n",
    "fig_con, ax_con = plt.subplots(1,2)\n",
    "ax_con[0].imshow(image_ori)\n",
    "ax_con[1].imshow(image_con)\n",
    "ax_con[0].set_axis_off()\n",
    "ax_con[1].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Resize all images to a fixed resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resized = ResizeTransformer().transform(X_train)\n",
    "X_test_resized = ResizeTransformer().transform(X_test)\n",
    "print(X_train_resized.shape)\n",
    "print(X_test_resized.shape)\n",
    "\n",
    "# Show effect of resizing\n",
    "image_index = 17\n",
    "image_ori = Image.fromarray(X_train[image_index])\n",
    "image_res = Image.fromarray(X_train_resized[image_index])\n",
    "# create figure and show images\n",
    "fig_res, ax_res = plt.subplots(1,2)\n",
    "ax_res[0].imshow(image_ori)\n",
    "ax_res[1].imshow(image_res)\n",
    "ax_res[0].set_axis_off()\n",
    "ax_res[1].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Extraction\n",
    "\n",
    "## 2.1. Aspect Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_ratio = [get_ratio(img) for img in X_train]\n",
    "\n",
    "plt.ylim(0,5)\n",
    "plt.xlabel(\"Class index\")\n",
    "plt.ylabel(\"Aspect Ratio\")\n",
    "plt.title(\"Distribution of aspect ratio among training samples.\")\n",
    "plt.scatter(y_train, aspect_ratio, alpha=0.42, s=1)"
   ]
  },
  {
   "source": [
    "## 2.1. Color Histograms"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbinh=3\n",
    "X_train_hist = colorhistTransformer(nbin=nbinh).transform(X_train)\n",
    "X_test_hist = colorhistTransformer(nbin=nbinh).transform(X_test)\n",
    "print(X_train_hist.shape)\n",
    "print(X_test_hist.shape)\n",
    "\n",
    "# Show corresponding image\n",
    "image_index = 99\n",
    "image_ori = Image.fromarray(X_train[image_index])\n",
    "# create figure and show images\n",
    "fig_rgb, ax_rgb = plt.subplots()\n",
    "ax_rgb.imshow(image_ori)\n",
    "ax_rgb.set_axis_off()\n",
    "\n",
    "def image_plot(hist,image,colors):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(np.arange(len(hist)),hist,width=1,color=colors,linewidth=0)\n",
    "colors=[]\n",
    "for r in np.arange(0.5,nbinh+0.5):\n",
    "    for g in np.arange(0.5,nbinh+0.5):\n",
    "        for b in np.arange(0.5,nbinh+0.5):\n",
    "            colors.append((r/nbinh,g/nbinh,b/nbinh))\n",
    "image_plot(X_train_hist[image_index],X_train[image_index],colors*256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hog = HogTransformer().transform(X_train_resized)\n",
    "X_test_hog = HogTransformer().transform(X_test_resized)\n",
    "print(X_train_hog.shape)\n",
    "print(X_test_hog.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Visualization\n",
    "\n",
    "## 3.1 Histogram for 1 HOG feature\n",
    "A histogram that plots the number of samples with certain HOG values for 1 specific HOG feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the histogram for a specific feature\n",
    "feature_index = 9\n",
    "feature = X_train_hog[:,feature_index]\n",
    "fig_feat, ax_feat = plt.subplots()\n",
    "ax_feat.set_title(\"Histogram for feature {}\".format(feature_index))\n",
    "ax_feat.set_xlabel(\"HOG values\")\n",
    "ax_feat.set_ylabel(\"number of samples\")\n",
    "plot_histogram(ax_feat, feature, bins=50)"
   ]
  },
  {
   "source": [
    "## 3.2 HOG features for 1 sample"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of HOG features (NOTE: uses skimage HOG)\n",
    "from skimage.feature import hog\n",
    "\n",
    "image_index = 7\n",
    "image_original = X_train_resized[image_index]\n",
    "fd, image_hog = hog(image_original, orientations=9, pixels_per_cell=(8, 8),\n",
    "                    cells_per_block=(8, 8), visualize=True, multichannel=True)\n",
    "\n",
    "fig_hog, ax_hog = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "ax_hog[0].imshow(image_original)\n",
    "ax_hog[1].imshow(image_hog)\n",
    "ax_hog[0].set_axis_off()\n",
    "ax_hog[1].set_axis_off()\n",
    "print(fd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Color histogram for 1 sample\n",
    "A histogram that plots the number of features with certain HOG values for 1 specific sample. There's also a function implemented to plot histograms for multiple samples. This is to visually check for correlations between samples and try to understand what the poleIDs and IDs play as roles in the dataset.\n",
    "Note that samples with different poleIDs but identical IDs have (visually) identical histograms. This implies a correlation between these samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the histogram for a specific sample\n",
    "sample_index = 99\n",
    "sample = X_train_hog[sample_index,:]\n",
    "image = Image.fromarray(X_train[sample_index])\n",
    "#image.show() # uncomment to show corresponding images\n",
    "fig_samp, ax_samp = plt.subplots()\n",
    "ax_samp.set_title(\"Histogram for sample {}\".format(sample_index))\n",
    "ax_samp.set_xlabel(\"HOG values\")\n",
    "ax_samp.set_ylabel(\"number of features\")\n",
    "plot_histogram(ax_samp, sample, bins=50)\n",
    "fig_im, ax_im = plt.subplots()\n",
    "ax_im.imshow(image)\n",
    "ax_im.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Feature Combination\n",
    "Combine HOG and color features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr = LogisticRegression(max_iter=1000, n_jobs=-2)  \n",
    "rfe = RFE(estimator= clf_lr , step =50)  \n",
    "# inx=np.random.randint(0,len(X_train)-1,1000)\n",
    "# fit = rfe.fit(X_train_hog[inx,:], y_train[inx])\n",
    "\n",
    "X_train_hog_hist = np.concatenate((X_train_hog, X_train_hist), axis=1)\n",
    "X_test_hog_hist = np.concatenate((X_test_hog, X_test_hist), axis=1)\n",
    "print(X_train_hog_hist.shape)\n",
    "print(X_test_hog_hist.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Feature Correlations\n",
    "We can also look at the correlations between feature pairs. Multiple correlation coefficient calculation methods are possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also look at the correlations between feature pairs \n",
    "# and between the features and the labels\n",
    "\n",
    "# turn numpy X_train into pd dataframe and add column with labels\n",
    "row_names = [i for i in range(1,number_of_train_samples+1)]\n",
    "column_names = ['HOG'+ str(i) for i in range(1,X_train_hog.shape[1]+1)]\n",
    "column_names += ['COL' + str(i) for i in range(1,nbinh**3+1) ]\n",
    "pd_X_train_hog_hist = pd.DataFrame(data=X_train_hog_hist, \n",
    "                                  index=row_names,\n",
    "                                        columns=column_names)\n",
    "pd_X_train_hog_hist['class'] = y_train\n",
    "pd_X_train_hog_hist.head()\n",
    "plot_correlation_matrix(pd_X_train_hog_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check the # of ftrs eleminated by transformming \n",
    "for t in [.75]:#,.8,.85,.9\n",
    "    X_train_corrTrunc = CorrMatrixTransformer(treshold=t).transform(X_train_hog, y_train)\n",
    "    print(f'Threshold value {t}')\n",
    "    print(X_train_corrTrunc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation strategy -- stratified and grouped\n",
    "cv_indices = []\n",
    "folds = 5\n",
    "sgkf = stratified_group_k_fold(X_train, y_train, p_train, k=folds)\n",
    "for train_fold, test_fold in sgkf:\n",
    "    cv_indices.append((train_fold, test_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning ranges\n",
    "boolean = [True, False]\n",
    "lr_weights = ['balanced', None]\n",
    "lr_C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "lr_class = ['ovr', 'multinomial']\n",
    "hog_sizes = [64, 32]\n",
    "hog_bins = [5, 9, 13]\n",
    "hist_bin= [2, 3, 4]\n",
    "lda_solvers = ['svd', 'lsqr', 'eigen']\n",
    "lda_shrinkage = np.arange(0, 1, 0.2)\n",
    "corr_treshold = [.8,.85,.9]\n",
    "corr_treshold = [.02]\n",
    "corr_method_list = ['pearson', 'kendall', 'spearman'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different pipeline sections\n",
    "pipeline_hog = Pipeline([('resize', ResizeTransformer()),\n",
    "                        ('hog', HogTransformer(winSize=32, blockSize=32, \n",
    "                                    blockStride=2, cellSize=8,\n",
    "                                    nbins=15))\n",
    "                        ])\n",
    "pipeline_colorhist = Pipeline([('colorhist', colorhistTransformer(nbin=4))])\n",
    "pipeline_aspect_ratio = Pipeline([('aspect_ratio', AspectRatioTransformer())])\n",
    "\n",
    "# combinated\n",
    "union = FeatureUnion([('HOG', pipeline_hog), \n",
    "                     ('COLOR', pipeline_colorhist),\n",
    "                     ('REST', pipeline_aspect_ratio)\n",
    "                     ])\n",
    "\n",
    "pipeline = Pipeline([('union', union),\n",
    "                    ('scalar', StandardScaler()),\n",
    "                    ('classify_lr', LogisticRegression(max_iter=1000, n_jobs=-2))\n",
    "                    ])\n",
    "\n",
    "\n",
    "# parameter grid\n",
    "param_grid = {'classify_lr__C':[.1]} # short search\n",
    "\n",
    "# perform grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=cv_indices, \n",
    "                            scoring=neg_logloss_scorer, verbose=True, \n",
    "                            n_jobs=-1, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train, groups=p_train)\n",
    "show_grid_scores(grid_search)\n",
    "\n",
    "# get best model and calculate score\n",
    "estimator = get_best_model(grid_search)\n",
    "scores = cross_validate(estimator, X_train, y_train, groups=p_train, \n",
    "                        cv=cv_indices, scoring=neg_logloss_scorer, return_train_score=True)\n",
    "show_scores(scores)\n",
    "\n",
    "show_misclassifications(pipeline, X_train, y_train, cv_indices, 1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Evaluation\n",
    "\n",
    "## 5.1. Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation curves for 2 dimensional grid search, containing C\n",
    "plot_grid_search(grid_search.cv_results_, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation curve for 1 dimensional grid search, any hyperparameter\n",
    "# Note: this performs a gridsearch and is very slow\n",
    "param_name = 'classify_lr__C'\n",
    "param_range = param_grid[param_name]\n",
    "valid_curv = validation_curve(estimator, X_train, y_train, param_name=param_name, param_range=param_range, \n",
    "                                cv=cv_indices, groups=p_train, scoring=neg_logloss_scorer, \n",
    "                                    n_jobs=-2)\n",
    "plot_validation_curve(valid_curv, param_name, param_range, xscale=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and plot learning curve\n",
    "learn_curv = learning_curve(estimator, X_train, y_train, train_sizes=np.linspace(.1, 1.0, 5),\n",
    "                                cv=cv_indices, groups=p_train, scoring=neg_logloss_scorer, \n",
    "                                    n_jobs=-2, shuffle=True)\n",
    "plot_learning_curve(learn_curv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix and corresponding misclassified images for a certain fold\n",
    "show_misclassifications(estimator, X_train, y_train, cv_indices, fold_number=1, N=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train best model using all training data\n",
    "estimator.fit(X_train, y_train)\n",
    "# Here is where we create the submission for your estimator\n",
    "output_probabilities = estimator.predict_proba(X_test)\n",
    "create_submission(output_probabilities, 'submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}